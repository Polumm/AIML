# AIML

Keywords: Artificial Intelligence, Machine Learning, Deep Learning, Algorithm Implementation, DecisionTree, FCM, KMeans, KNN, LeNet, Linear Regression, Logistic Regression, Naive Bayes, Datasets, Framework Optimization, Unified Operation, Algorithm Performance.

This project encompasses the source code implementation for the course of Artificial Intelligence and Machine Learning. In this course, I have explored classic algorithms of machine learning and deep learning, including Linear Regression, Logistic Regression, DecisionTree, KMeans (and FCM), KNN (and KDTree), Naive Bayes, LeNet, among others. These algorithms were implemented and open-sourced within a unified and convenient framework. Supported datasets include Bouston, IndianPine, PaviaU, Iris, Mnist, and Mudou, among others.

Within this project, I focused on the fundamental principles and performance-impacting factors of the classic algorithms such as DecisionTree, FCM, KMeans, KNN, LeNet, Linear Regression, Logistic Regression, and Naive Bayes. For each algorithm, I delved into how different parameters, diverse datasets, and the application of performance optimization methods influence the performance and results of the algorithms.

Furthermore, I have optimized the framework for greater integration and user-friendliness. This project has low code coupling, facilitates modification and enhancement, and fosters more extensive experimentation. It supports batch experiments and automatically saves experiment parameters and results. This automated training mode alleviates the experimental burden for researchers to a certain extent. Research results reveal that for common machine learning algorithms, appropriate parameter selection, integration of optimization algorithms, and suitable dataset split ratios can enhance algorithm performance.
